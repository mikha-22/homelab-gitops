# apps/opentelemetry-demo/values.yaml - SIMPLIFIED: Direct to LGTM Stack

# Global settings
global:
  domain: milenika.dev

# Configure OpenTelemetry Collector to send data directly to your LGTM stack
opentelemetry-collector:
  enabled: true
  config:
    connectors:
      # Add the spanmetrics connector to generate RED metrics from traces
      spanmetrics:
        histogram:
          explicit:
            buckets: [100us, 1ms, 2ms, 6ms, 10ms, 100ms, 250ms]
        dimensions:
          - name: http.method
            default: GET
          - name: http.status_code
          - name: service.name
        exemplars:
          enabled: true
        aggregation_temporality: "AGGREGATION_TEMPORALITY_CUMULATIVE"
        metrics_flush_interval: 15s
        
    exporters:
      # Send traces to your Tempo instance
      otlp/tempo:
        endpoint: http://tempo.monitoring.svc.cluster.local:4317
        tls:
          insecure: true
      
      # Send metrics directly to your Prometheus
      prometheusremotewrite:
        endpoint: http://prometheus-stack-kube-prom-prometheus.monitoring.svc.cluster.local:9090/api/v1/write
        remote_write_queue:
          enabled: true
          queue_size: 10000
          num_consumers: 5
      
      # Send logs to your Loki
      loki:
        endpoint: http://loki-gateway.monitoring.svc.cluster.local:3100/loki/api/v1/push
        
      # Keep debug for troubleshooting
      debug:
        verbosity: normal
        
    service:
      pipelines:
        traces:
          receivers: [otlp]
          processors: [batch, memory_limiter]
          exporters: [spanmetrics, otlp/tempo, debug]  # spanmetrics generates metrics from traces
        metrics:
          receivers: [otlp, spanmetrics]  # FIXED: spanmetrics as receiver for generated metrics
          processors: [batch, memory_limiter]
          exporters: [prometheusremotewrite, debug]
        logs:
          receivers: [otlp]
          processors: [batch, memory_limiter]
          exporters: [loki, debug]

# Enable the in-memory cache (valkey-cart)
components:
  # Frontend configuration - ADDED: browser telemetry config
  frontend:
    resources:
      limits:
        memory: 200Mi
        cpu: 200m
      requests:
        memory: 100Mi
        cpu: 100m
    envOverrides:
      - name: PUBLIC_OTEL_EXPORTER_OTLP_TRACES_ENDPOINT
        value: https://otel-demo.milenika.dev/otlp-http/v1/traces

  # Frontend proxy with ingress for external access
  frontendProxy:
    enabled: true
    resources:
      limits:
        memory: 100Mi
        cpu: 100m
      requests:
        memory: 50Mi
        cpu: 50m
    service:
      type: ClusterIP
    ingress:
      enabled: true
      ingressClassName: traefik
      annotations:
        external-dns.alpha.kubernetes.io/target: "e0995bb5-0641-44ba-9ac6-533e678117a2.cfargotunnel.com"
        external-dns.alpha.kubernetes.io/cloudflare-proxied: "true"
        traefik.ingress.kubernetes.io/router.middlewares: "monitoring-security-headers@kubernetescrd"
      hosts:
        - host: otel-demo.milenika.dev
          paths:
            - path: /
              pathType: Prefix
              port: 8080
      tls:
        - secretName: otel-demo-tls
          hosts:
            - otel-demo.milenika.dev

  # Other services - reduce resource usage for homelab
  adService:
    resources:
      limits:
        memory: 300Mi
        cpu: 200m
      requests:
        memory: 180Mi
        cpu: 100m

  cartService:
    resources:
      limits:
        memory: 200Mi
        cpu: 200m
      requests:
        memory: 160Mi
        cpu: 100m

  checkoutService:
    resources:
      limits:
        memory: 200Mi
        cpu: 200m
      requests:
        memory: 100Mi
        cpu: 100m

  currencyService:
    resources:
      limits:
        memory: 200Mi
        cpu: 200m
      requests:
        memory: 100Mi
        cpu: 100m

  emailService:
    resources:
      limits:
        memory: 200Mi
        cpu: 200m
      requests:
        memory: 100Mi
        cpu: 100m

  paymentService:
    resources:
      limits:
        memory: 200Mi
        cpu: 200m
      requests:
        memory: 100Mi
        cpu: 100m

  productCatalogService:
    resources:
      limits:
        memory: 200Mi
        cpu: 200m
      requests:
        memory: 100Mi
        cpu: 100m

  recommendationService:
    resources:
      limits:
        memory: 500Mi  # This one needs more memory
        cpu: 200m
      requests:
        memory: 200Mi
        cpu: 100m

  shippingService:
    resources:
      limits:
        memory: 200Mi
        cpu: 200m
      requests:
        memory: 100Mi
        cpu: 100m

  # Load generator - reduce load for homelab
  loadgenerator:
    enabled: true
    resources:
      limits:
        memory: 200Mi
        cpu: 200m
      requests:
        memory: 100Mi
        cpu: 100m
    env:
      - name: LOCUST_WEB_PORT
        value: "8089"
      - name: LOCUST_USERS
        value: "5"  # Reduced load
      - name: LOCUST_SPAWN_RATE
        value: "1"  # Slower spawn rate
      - name: LOCUST_HOST
        value: "http://frontend:8080"

# Disable components we don't need (you already have these)
jaeger:
  enabled: false

prometheus:
  enabled: false
  
grafana:
  enabled: false
  
opensearch:
  enabled: false
