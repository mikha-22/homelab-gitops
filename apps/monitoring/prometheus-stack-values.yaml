# apps/monitoring/prometheus-stack-values.yaml

# Global settings
global:
  imageRegistry: ""
  imagePullSecrets: []

# CRDs configuration
crds:
  enabled: true

# Disable AlertManager for simplified homelab setup
alertmanager:
  enabled: false

# Grafana Configuration
grafana:
  enabled: true
  
  # Admin credentials
  adminUser: admin
  adminPassword: null

  admin:
    existingSecret: grafana-admin-secret
    userKey: admin-user
    passwordKey: admin-password
    
  # Pod disruption budget
  podDisruptionBudget:
    enabled: true
    minAvailable: 0
  
  # Disable problematic init container
  initChownData:
    enabled: false
  
  # Persistence
  persistence:
    enabled: true
    type: pvc
    storageClassName: local-path
    size: 10Gi
    accessModes:
      - ReadWriteOnce
  
  # Resource management
  resources:
    limits:
      cpu: 500m
      memory: 512Mi
    requests:
      cpu: 250m
      memory: 256Mi
  
  # Security context
  securityContext:
    runAsNonRoot: true
    runAsUser: 472
    fsGroup: 472
    
  # Health probes
  livenessProbe:
    httpGet:
      path: /api/health
      port: 3000
    initialDelaySeconds: 30
    periodSeconds: 10
    timeoutSeconds: 5
    failureThreshold: 3
    
  readinessProbe:
    httpGet:
      path: /api/health
      port: 3000
    initialDelaySeconds: 5
    periodSeconds: 5
    timeoutSeconds: 3
    failureThreshold: 3
  
  # Ingress configuration
  ingress:
    enabled: true
    ingressClassName: traefik
    annotations:
      "external-dns.alpha.kubernetes.io/target": "e0995bb5-0641-44ba-9ac6-533e678117a2.cfargotunnel.com"
      "external-dns.alpha.kubernetes.io/cloudflare-proxied": "true"
    hosts:
      - grafana.milenika.dev
    path: /
    pathType: Prefix
    tls:
      - secretName: grafana-tls
        hosts:
          - grafana.milenika.dev
  
  # Grafana configuration
  grafana.ini:
    server:
      root_url: "https://grafana.milenika.dev"
      serve_from_sub_path: false
    security:
      disable_gravatar: true
      cookie_secure: true
      cookie_samesite: "strict"
      strict_transport_security: true
      x_content_type_options: true
      x_xss_protection: true
    auth:
      disable_login_form: false
      disable_signout_menu: false
    "auth.anonymous":
      enabled: true
      org_name: "Main Org."
      org_role: "Viewer"
      hide_version: true
    analytics:
      reporting_enabled: false
      check_for_updates: false
    log:
      mode: "console"
      level: "info"
    panels:
      disable_sanitize_html: false

  additionalDataSources:
    - name: Loki
      type: loki
      access: proxy
      url: http://loki.monitoring.svc.cluster.local:3100
      isDefault: false
      version: 1
      editable: true
      jsonData:
        derivedFields:
          - datasourceUid: tempo
            matcherRegex: "trace[_-]?id[\"\\s:=]+([a-fA-F0-9]+)"
            name: TraceID
            url: "$${__value.raw}"
        
    - name: Tempo
      type: tempo
      access: proxy
      url: http://tempo.monitoring.svc.cluster.local:3200
      uid: tempo
      isDefault: false
      version: 1
      editable: true
      jsonData:
        # ADDED THIS BLOCK to link trace metrics to Prometheus
        tracesToMetrics:
          datasourceUid: 'prometheus'
          tags:
            - { key: 'service.name' }
            - { key: 'span.name' }
            - { key: 'job' }
          queries:
            - name: 'traces_spanmetrics_latency'
              query: 'sum(rate(traces_spanmetrics_latency_bucket{$$__tags}[$$__rate_interval])) by (le)'
            - name: 'traces_spanmetrics_calls'
              query: 'sum(rate(traces_spanmetrics_calls_total{$$__tags}[$$__rate_interval]))'
            - name: 'traces_spanmetrics_status_code'
              query: 'sum(rate(traces_spanmetrics_calls_total{$$__tags}[$$__rate_interval])) by (status_code)'

        tracesToLogs:
          datasourceUid: loki
          tags: ['job', 'instance', 'pod', 'namespace']
          mappedTags:
            - key: 'service.name'
              value: 'service'
            - key: 'service.namespace' 
              value: 'namespace'
          mapTagNamesEnabled: false
          spanStartTimeShift: '1h'
          spanEndTimeShift: '1h'
        serviceMap:
          datasourceUid: prometheus
        nodeGraph:
          enabled: true
        search:
          hide: false
        lokiSearch:
          datasourceUid: loki

  # Sidecar configuration
  sidecar:
    dashboards:
      enabled: true
      searchNamespace: ALL
      label: grafana_dashboard
      labelValue: "1"
      folder: /tmp/dashboards
      provider:
        foldersFromFilesStructure: true
    datasources:
      enabled: true
      searchNamespace: ALL
      label: grafana_datasource
      labelValue: "1"
      defaultDatasourceEnabled: true

# Prometheus Configuration
prometheus:
  enabled: true
  prometheusSpec:
    retention: 2d
    retentionSize: 5GB
    
    enableRemoteWriteReceiver: true
    
    resources:
      limits:
        cpu: 2000m
        memory: 4Gi
      requests:
        cpu: 1000m
        memory: 2Gi
    securityContext:
      runAsNonRoot: true
      runAsUser: 1000
      fsGroup: 2000
    storageSpec:
      volumeClaimTemplate:
        spec:
          storageClassName: local-path
          accessModes: ["ReadWriteOnce"]
          resources:
            requests:
              storage: 10Gi
    serviceMonitorSelectorNilUsesHelmValues: false
    podMonitorSelectorNilUsesHelmValues: false
    ruleSelectorNilUsesHelmValues: false
    serviceMonitorNamespaceSelector: {}
    podMonitorNamespaceSelector: {}
    ruleNamespaceSelector: {}
    scrapeInterval: 30s
    evaluationInterval: 30s

# Prometheus Operator
prometheusOperator:
  enabled: true
  resources:
    limits:
      cpu: 200m
      memory: 256Mi
    requests:
      cpu: 100m
      memory: 128Mi
  securityContext:
    runAsNonRoot: true
    runAsUser: 65534

# Node Exporter
nodeExporter:
  enabled: true
  resources:
    limits:
      cpu: 200m
      memory: 100Mi
    requests:
      cpu: 100m
      memory: 50Mi

# Kube State Metrics  
kubeStateMetrics:
  enabled: true
  resources:
    limits:
      cpu: 100m
      memory: 128Mi
    requests:
      cpu: 50m
      memory: 64Mi

# Default monitoring rules
defaultRules:
  create: true
  rules:
    alertmanager: false
    etcd: true
    configReloaders: true
    general: true
    k8s: true
    kubeApiserverAvailability: true
    kubeApiserverBurnrate: true
    kubeApiserverHistogram: true
    kubeApiserverSlos: true
    kubelet: true
    kubeProxy: true
    kubePrometheusGeneral: true
    kubePrometheusNodeRecording: true
    kubernetesApps: true
    kubernetesResources: true
    kubernetesStorage: true
    kubernetesSystem: true
    network: true
    node: true
    nodeExporterAlerting: true
    nodeExporterRecording: true
    prometheus: true
    prometheusOperator: true

# Cleanup settings
cleanPrometheusOperatorObjectNames: true

# Disable trackTimestampsStaleness globally to fix schema error
kubeStateMetrics:
  enabled: true
  serviceMonitor:
    trackTimestampsStaleness: false

nodeExporter:
  enabled: true
  serviceMonitor:
    trackTimestampsStaleness: false

# Also disable for any other ServiceMonitors that might have it
kubelet:
  serviceMonitor:
    trackTimestampsStaleness: false

kubeControllerManager:
  serviceMonitor:
    trackTimestampsStaleness: false

kubeScheduler:
  serviceMonitor:
    trackTimestampsStaleness: false

kubeProxy:
  serviceMonitor:
    trackTimestampsStaleness: false

kubeEtcd:
  serviceMonitor:
    trackTimestampsStaleness: false
