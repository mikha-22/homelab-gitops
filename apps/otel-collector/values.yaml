# apps/otel-collector/values.yaml - CORRECT OFFICIAL PATTERN

# 1. Set the deployment mode to daemonset.
mode: daemonset

# 2. Specify the collector image and version.
image:
  repository: otel/opentelemetry-collector-contrib
  tag: 0.131.0

# 3. Configure ports correctly.
ports:
  # Disable default port definitions to prevent conflicts
  otlp:
    enabled: false
  otlp-http:
    enabled: false
  # Define only the gRPC port we need with hostPort
  otlp-grpc:
    enabled: true
    containerPort: 4317
    hostPort: 4317
    protocol: TCP
    servicePort: 4317
  # Add HTTP port as well for completeness
  # Add metrics port for Prometheus scraping
  metrics:
    enabled: true
    containerPort: 8888
    protocol: TCP
    servicePort: 8888

# 4. Enable presets for Kubernetes log collection and metadata
presets:
  # Enable log collection from all Kubernetes pods
  logsCollection:
    enabled: true
  # Enable Kubernetes metadata enrichment for all telemetry
  kubernetesAttributes:
    enabled: true
    # Extract pod labels and annotations for better correlation
    extractAllPodLabels: true
    extractAllPodAnnotations: true

# 5. Define the collector's pipeline configuration - OFFICIAL PATTERN
config:
  receivers:
    otlp:
      protocols:
        grpc:
          # OFFICIAL PATTERN: Use pod IP with hostPort mapping
          endpoint: ${env:MY_POD_IP}:4317
        http:
          endpoint: ${env:MY_POD_IP}:4318

  processors:
    batch: {}
    memory_limiter:
      check_interval: 1s
      limit_mib: 512
      spike_limit_mib: 128

  exporters:
    # ENABLE DEBUG EXPORTER
    debug:
      verbosity: detailed
      sampling_initial: 5
      sampling_thereafter: 200
    
    # Exporter for TRACES -> Tempo
    otlp/tempo:
      endpoint: "tempo.monitoring.svc.cluster.local:4317"
      tls:
        insecure: true

    # Exporter for METRICS -> Prometheus
    prometheusremotewrite:
      endpoint: "http://prometheus-stack-kube-prom-prometheus.monitoring.svc.cluster.local:9090/api/v1/write"
      tls:
        insecure: true

    # Exporter for LOGS -> Loki  
    otlphttp/loki:
      endpoint: "http://loki.monitoring.svc.cluster.local:3100/otlp"

  service:
    pipelines:
      traces:
        receivers: [otlp]
        processors: [memory_limiter, k8sattributes, batch]
        exporters: [debug, otlp/tempo]
      metrics:
        receivers: [otlp]
        processors: [memory_limiter, k8sattributes, batch]
        exporters: [debug, prometheusremotewrite]
      logs:
        # Now includes both OTLP logs (from apps) AND filelog (from Kubernetes)
        receivers: [otlp, filelog]
        processors: [memory_limiter, k8sattributes, batch]
        exporters: [debug, otlphttp/loki]

# 6. Resource limits for the collector
resources:
  limits:
    cpu: 1000m
    memory: 1Gi
  requests:
    cpu: 500m
    memory: 512Mi

# 7. Security context
securityContext:
  runAsUser: 0  # Required to read host log files
  runAsGroup: 0
  privileged: false
  readOnlyRootFilesystem: false
  allowPrivilegeEscalation: false

# 8. Node selector and tolerations for DaemonSet deployment
nodeSelector: {}
tolerations:
  # Allow running on control plane nodes if needed
  - key: node-role.kubernetes.io/control-plane
    operator: Exists
    effect: NoSchedule
  - key: node-role.kubernetes.io/master
    operator: Exists
    effect: NoSchedule

# 9. Service monitor for Prometheus scraping
serviceMonitor:
  enabled: true
  labels:
    release: prometheus-stack
